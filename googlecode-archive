#!/usr/bin/env bash

# Copyright (c) 2016-2017, Cody Opel <codyopel@gmail.com>
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name of the copyright holder nor the names of its contributors
#   may be used to endorse or promote products derived from this software
#   without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# Dependencies:
# bash >=4.2
# coreutils
# curl >=7.52.0 w/ OpenSSL & HTTP2
# grep
# jq
# tar
# unzip
# xargs
# xz

set -o errexit
set -o pipefail

LIB_BASH="$(
  readlink -f "$(
    readlink -f "$(
      dirname "$(
        readlink -f "${0}"
      )"
    )"
  )/vendor/lib-bash/src/share/lib-bash/lib.bash"
)"

if [ -f "${LIB_BASH}" ]; then
  source "${LIB_BASH}"
elif type 'git' > /dev/null; then
  git submodule update --init --recursive
  source "${LIB_BASH}"
else
  echo 'ERROR: lib-bash is missing'
  exit 1
fi

# URL
declare -r GSAPI='https://storage.googleapis.com'
# Buckets
declare -r ABK='google-code-archive'
declare -r ASBK='google-code-archive-source'
declare -r ATBK='google-code-attachments'
declare -r DBK='google-code-archive-downloads'
# API
# 'v2/apache-extras.org'
# 'v2/eclipselabs.org'
declare -r CGC="${API:-v2/code.google.com}"

declare -r OUTDIRDEFAULT=`pwd`
declare -r OUTDIR="${OUTDIR:-${OUTDIRDEFAULT}}"

CONCURRENT_COMPACT='true'
CONCURRENT_LIMIT='50'
declare -r ENABLE_DEBUGGING='false'

CURL_ARGS=(
  '--continue-at -'
  '--http2'
  '--http2-prior-knowledge'
  '--ssl-reqd'
  '--tlsv1.2'
  '--ciphers ECDHE-RSA-AES256-GCM-SHA384'
  '--proto -all,https'
  '--proto-redir -all,https'
  '--max-redirs 0'
  '--speed-limit 10240'
  '--speed-time 10'
  '--retry 3'
  '--retry-delay 5'
  '--compressed'
  '--create-dirs'
  # Restrict-View-* files are not contained in the archive and return 403.
  '--fail'
)

GoogleCode::CommitsPages() {
  local -r Name="${1}"
  local -i NumPages

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/commits-page-1.json"
  eval curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ABK}/${CGC}/${Name}/commits-page-1.json" \
    -o "${OUTDIR}/${Name}/commits-pages/commits-page-1.json"

  NumPages="$(
    jq -r -c -M '.TotalPages' \
      "${OUTDIR}/${Name}/commits-pages/commits-page-1.json"
  )"

  Var::Type.integer "${NumPages}"

  if [ ${NumPages} -gt 1 ]; then
    Log::Message 'info' \
      "${GSAPI}/${ABK}/${CGC}/${Name}/commits-page-[2-${NumPages}].json"
    eval curl ${CURL_ARGS[@]} \
      "${GSAPI}/${ABK}/${CGC}/${Name}/commits-page-[2-${NumPages}].json" \
      -o "${OUTDIR}/${Name}/commits-pages/commits-page-#1.json"
  fi
}

GoogleCode::Downloads.file() {
  local -r DownloadFile="${2}"
  local -r Name="${1}"

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/${DownloadFile}"
  curl ${CURL_ARGS[@]} "${GSAPI}/${DBK}/${CGC}/${Name}/${DownloadFile}" \
    -o "${OUTDIR}/${Name}/downloads/${DownloadFile}"
}

GoogleCode::Downloads.pages() {
  local -r DownloadPageNum="${2}"
  local -r Name="${1}"

  curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ABK}/${CGC}/${Name}/downloads-page-${DownloadPageNum}.json" \
    -o "${OUTDIR}/${Name}/downloads-pages/downloads-page-${DownloadPageNum}.json"
}

# TODO: vailidate download against provided sha1 hash
GoogleCode::Downloads() {
  local -a CCArgs
  local DownloadFile
  local DownloadFiles
  local -r Name="${1}"
  local NumPages

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/downloads-page-1.json"
  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/downloads-page-1.json" \
    -o "${OUTDIR}/${Name}/downloads-pages/downloads-page-1.json" || :

  if [ ! -f "${OUTDIR}/${Name}/downloads-pages/downloads-page-1.json" ]; then
    Log::Message 'info' 'project has no downloads'
    return 0
  fi

  NumPages="$(
    jq -r -c -M '.totalPages' \
      "${OUTDIR}/${Name}/downloads-pages/downloads-page-1.json"
  )"

  if [ ${NumPages} -gt 1 ]; then
    Log::Message 'info' \
      "${GSAPI}/${ABK}/${CGC}/${Name}/commits-page-[2-${NumPages}].json"
    curl ${CURL_ARGS[@]} \
      "${GSAPI}/${ABK}/${CGC}/${Name}/commits-page-[2-${NumPages}].json" \
      -o "${OUTDIR}/${Name}/downloads-pages/downloads-page-#1.json"
  fi

  while read DownloadPageFile; do
    while read DownloadFile; do
      DownloadFiles="${DownloadFiles}${DownloadFiles:+,}${DownloadFile}"
    done < <(jq -r -c -M '.downloads[].filename' "${DownloadPageFile}")
  done < <(find "${OUTDIR}/${Name}/downloads-pages" -type f -name '*downloads-page*.json')

  GoogleCode::Step 'fetching downloads'

  Log::Message 'info' "${GSAPI}/${DBK}/${CGC}/${Name}/{${DownloadFiles}}"
  curl ${CURL_ARGS[@]} "${GSAPI}/${DBK}/${CGC}/${Name}/{${DownloadFiles}}" \
    -o "${OUTDIR}/${Name}/downloads/#1"
}

GoogleCode::Issues.attachment() {
  local -i ExitStatus
  local -r File="${4}"
  local -r IssueCommentNum="${3}"
  local -r IssueNum="${2}"
  local -r Name="${1}"

  set +o errexit

  curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ATBK}/${Name}/issue-${IssueNum}/comment-${IssueCommentNum}/${File}" \
    -o "${OUTDIR}/${Name}/issues/${IssueNum}/${IssueCommentNum}/${File}"
  ExitStatus=$?

  set -o errexit

  # Ignore 403 Restrict-View-* failures
  if [ ${ExitStatus} == 22 ]; then
    ExitStatus=0
  fi

  return ${ExitStatus}
}

GoogleCode::Issues() {
  local Attachment
  local -a Attachments
  local -a CCArgs1
  local -a CCArgs2
  local IssueCommentNum
  local IssueNum
  local -a IssuePagesArray
  local Name="${1}"
  local NumIssues
  local NumIssuesRange
  local NumPages
  local NumPagesRange

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/issues-page-1.json"
  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/issues-page-1.json" \
    -o "${OUTDIR}/${Name}/issues-pages/issues-page-1.json" || :

  if [ ! -f "${OUTDIR}/${Name}/issues-pages/issues-page-1.json" ]; then
    Log::Message 'info' 'project contains no issues'
    return 0
  fi

  NumIssues="$(
    jq -r -c -M 'first(.issues[].id)' \
      "${OUTDIR}/${Name}/issues-pages/issues-page-1.json"
  )"
  NumPages="$(
    jq -r -c -M '.totalPages' \
      "${OUTDIR}/${Name}/issues-pages/issues-page-1.json"
  )"

  Var::Type.integer "${NumIssues}"
  Var::Type.integer "${NumPages}"

  if [ ${NumPages} -gt 1 ]; then
    eval curl ${CURL_ARGS[@]} \
      "${GSAPI}/${ABK}/${CGC}/${Name}/issues-page-[2-${NumPages}].json" \
      -o "${OUTDIR}/${Name}/issues-pages/issues-page-#1.json"
  fi

  # Curl can't glob [1-1]
  if [ ${NumIssues} -gt 1 ]; then
    NumIssuesRange="[1-${NumIssues}]"
  fi
  eval curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ABK}/${CGC}/${Name}/issues/issue-${NumIssuesRange:-NumIssues}.json" \
    -o "${OUTDIR}/${Name}/issues/#1/issue-#1.json"

  GoogleCode::Step 'compiling list of attachments'

  while read IssueFile; do
    if [ ! -f "${IssueFile}" ]; then
      continue
    fi

    IssueNum="$(jq -r -c -M '.id' "${IssueFile}")"
    Var::Type.integer "${IssueNum}"

    if [ -f "${OUTDIR}/${Name}/IssueCommentJson" ]; then
      rm "${OUTDIR}/${Name}/IssueCommentJson"
    fi
    jq -r -c -M '.comments' "${IssueFile}" > "${OUTDIR}/${Name}/IssueCommentJson"

    while read IssueCommentNum; do
      Var::Type.integer "${IssueCommentNum}"

      if [ -f "${OUTDIR}/${Name}/IssueAttachmentsJson" ]; then
        rm "${OUTDIR}/${Name}/IssueAttachmentsJson"
      fi
      jq -r -c -M ".[]|select(.id | contains(${IssueCommentNum}))|.attachments" \
        "${OUTDIR}/${Name}/IssueCommentJson" > \
        "${OUTDIR}/${Name}/IssueAttachmentsJson"

      while read IssueAttachmentFile; do
        Attachments+=("${IssueAttachmentFile}")
      done < <(jq -r -c -M '.[]|.fileName' "${OUTDIR}/${Name}/IssueAttachmentsJson")

      for Attachment in "${Attachments[@]}"; do
        CCArgs2+=(
          '-'
          "fetching issue: ${IssueNum}, comment: ${IssueCommentNum}, attachment: ${Attachment}"
          GoogleCode::Issues.attachment
            "${Name}"
            "${IssueNum}"
            "${IssueCommentNum}"
            "${Attachment}"
        )
      done
      unset Attachments
    done < <(jq -r -c -M '.[]|.id' "${OUTDIR}/${Name}/IssueCommentJson")
  done < <(grep -r .fileName "${OUTDIR}/${Name}/issues" | awk -F: '{print $1}')

  GoogleCode::Step 'fetching issue attachements'

  [ ${#CCArgs2[@]} -ge 1 ] || return 0

  concurrent "${CCArgs2[@]}"

  if [ -f "${OUTDIR}/${Name}/IssueCommentJson" ]; then
    rm "${OUTDIR}/${Name}/IssueCommentJson"
  fi
  if [ -f "${OUTDIR}/${Name}/IssueAttachmentsJson" ]; then
    rm "${OUTDIR}/${Name}/IssueAttachmentsJson"
  fi
}

GoogleCode::Logo() {
  local Name="${1}"

  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/logo.png" \
    -o "${OUTDIR}/${Name}/logo.png"
}

GoogleCode::ProjectJson() {
  local -r Name="${1}"

  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/project.json" \
    -o "${OUTDIR}/${Name}/project.json"
}

# TODO: add support for sub repos, requires parsing project.json
# FIXME: check hasSource from project.json
GoogleCode::Repos() {
  local -r Name="${1}"

  curl ${CURL_ARGS[@]} "${GSAPI}/${ASBK}/${CGC}/${Name}/source-archive.zip" \
    -o "${OUTDIR}/${Name}/source-archive.zip"

  unzip -q "${OUTDIR}/${Name}/source-archive.zip" -d "${OUTDIR}/${Name}/repo/"

  rm "${OUTDIR}/${Name}/source-archive.zip"
}

GoogleCode::RemoveEmpty() {
  local Directory
  local -a Directories
  local IconSize
  local -r Name="${1}"
  local OutDirSize
  local ProjectJsonSize
  local TotalBytes

  sizeOf() {
    local -r Input="${1}"
    du -bs "${Input}" | awk '{print $1;exit}'
  }

  isEmpty() {
    local -r Dir="${1}"
    [ $(sizeOf "${Dir}") -eq 0 ] && return 0
    return 1
  }

  if [ -f "${OUTDIR}/${Name}/logo.png" ]; then
    IconSize=$(sizeOf "${OUTDIR}/${Name}/logo.png")
  fi
  OutDirSize=$(sizeOf "${OUTDIR}/${Name}")
  ProjectJsonSize=$(sizeOf "${OUTDIR}/${Name}/project.json")
  TotalBytes=$(( ${OutDirSize} - ${ProjectJsonSize} ${IconSize:+- ${IconSize}} ))
  # If the total number of bytes after subtracting logo,png & project.json
  # is less than 200 assume the project is empty an don't archive it.
  [ ${TotalBytes} -lt 200 ] && {
    Directory::Remove "${OUTDIR}/${Name}"
    return 1
  }

  while read Directory; do
    if isEmpty "${Directory}"; then
      Directories+=("${Directory}")
    fi
  done < <(
    # Don't risk collapsing VCS directories
    find "${OUTDIR}/${Name}" -type d -not -path "${OUTDIR}/${Name}/repo/*"
  )

  echo 'Removing empty directories:'
  printf '%s\n' "${Directories[@]}"

  # Sort directories by length, this works back up the directory
  # structure to prevent removing a parent before a child.
  echo "${Directories[@]}" |
    awk '{ print length(), $0 | "sort -n -r" }' |
    xargs rm -rf

  return 0
}

GoogleCode::SourcePages() {
  local -r Name="${1}"
  local -i NumPages

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/source-page-1.json"
  eval curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ABK}/${CGC}/${Name}/source-page-1.json" \
    -o "${OUTDIR}/${Name}/source-pages/source-page-1.json"

  NumPages="$(
    jq -r -c -M '.TotalPages' \
      "${OUTDIR}/${Name}/source-pages/source-page-1.json"
  )"

  Var::Type.integer "${NumPages}"

  if [ ${NumPages} -gt 1 ]; then
    Log::Message 'info' \
      "${GSAPI}/${ABK}/${CGC}/${Name}/source-page-[2-${NumPages}].json"
    eval curl ${CURL_ARGS[@]} \
      "${GSAPI}/${ABK}/${CGC}/${Name}/source-page-[2-${NumPages}].json" \
      -o "${OUTDIR}/${Name}/source-pages/source-page-#1.json"
  fi
}

GoogleCode::Step() {
  local -r Step="${1}"

  echo "########## ${Step} ##########">&1
}

GoogleCode::TarOutput() {
  local -r Name="${1}"

  File::Remove "${OUTDIR}/${Name}.tar.xz"

  # Before taring check that there is anything to tar and
  # remove any empty directories.
  GoogleCode::Step 'collapsing empty directories'
  GoogleCode::RemoveEmpty "${Name}" || return 0

  GoogleCode::Step 'tarring output'

  # Prevent full directory heirarchy from being included, use
  # a relative path.
  pushd "${OUTDIR}" > /dev/null
    tar -cf - "${Name}" |
      xz \
        -9 \
        --compress \
        --extreme \
        --threads 1 \
        - > "${Name}.tar.xz"
  popd > /dev/null

  Directory::Remove "${OUTDIR}/${Name}"
}

GoogleCode::Wikis() {
  local -a CCArgs
  local Files
  local -r Name="${1}"
  local WikiFile
  local -a WikiFiles

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/wikis.json"
  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/wikis.json" \
    -o "${OUTDIR}/${Name}/wikis.json" || :

  if [ ! -f "${OUTDIR}/${Name}/wikis.json" ]; then
    Log::Message 'info' 'project contains no wikis'
    return 0
  fi

  # Make sure not to interate over null
  [ -z "$(cat "${OUTDIR}/${Name}/wikis.json" |
          grep -o '{"WikiFiles":null}' || :)" ] || return 0

  while read WikiFile; do
    # Remove leading slash
    WikiFile="$(echo "${WikiFile}" | sed -e 's,^/,,')"
    WikiFiles+=("${WikiFile}")
  done < <(jq -r '.WikiFiles[]' "${OUTDIR}/${Name}/wikis.json")

  [ -n "${WikiFiles[*]}" ] || return 0

  for WikiFile in "${WikiFiles[@]}"; do
    Files+="${Files}${WikiFile:+,}${WikiFile}"
  done

  GoogleCode::Step 'fetching wiki pages'
  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/wiki/{${Files}}"
  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/wiki/{${Files}}" \
    -o "${OUTDIR}/${Name}/wikis/#1"
}

GoogleCode::Project() {
  local -r Name="${1}"
  local HasSource

  # Incase file were left from a previous run remove them to prevent
  # unwanted files.
  Directory::Remove "${OUTDIR}/${Name}" || return 1

  GoogleCode::ProjectJson "${Name}" || return 1

  GoogleCode::Step "checking for downloads"
  GoogleCode::Downloads "${Name}" || return 1

  GoogleCode::Step "checking for issues"
  GoogleCode::Issues "${Name}" || return 1

  GoogleCode::Step 'fetching logo'
  GoogleCode::Logo "${Name}" || return 1

  HasSource="$(jq -r -c -M '.hasSource' "${OUTDIR}/${Name}/project.json")"
  if [ "${HasSource}" == 'true' ]; then
    GoogleCode::Step 'fetching commits pages'
    GoogleCode::CommitsPages "${Name}" || return 1

    GoogleCode::Step 'fetching source pages'
    GoogleCode::SourcePages "${Name}" || return 1

    GoogleCode::Step 'fetching source code archive'
    GoogleCode::Repos "${Name}" || return 1
  fi

  GoogleCode::Step 'checking for wikis'
  GoogleCode::Wikis "${Name}" || return 1

  GoogleCode::TarOutput "${Name}" || return 1
}

GoogleCode::Main() {
  local -r Name="${1}"
  local -i Try=1

  # TCP connections could be dropped and it isn't worth implementing
  # detection for this, so loop until the program succeeds.
  while [ ${Try} -eq 1 ]; do
    GoogleCode::Project "${Name}" || {
      continue
    }
    Try=0
  done

  return 0
}

if [ -f "${1}" ]; then
  # TODO: support reading in file
  :
else
  [ -n "${1}" ] || {
    Log::Message 'error' "no input"
    exit 1
  }
  GoogleCode::Main "${1}"
fi

exit 0
