#!/usr/bin/env bash

# Copyright (c) 2016, Cody Opel <codyopel@gmail.com>
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice, this
#   list of conditions and the following disclaimer.
#
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
#
# * Neither the name of the copyright holder nor the names of its contributors
#   may be used to endorse or promote products derived from this software
#   without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# Dependencies:
# bash >=4.2
# coreutils
# curl >=7.49.0 w/ OpenSSL & HTTP2
# grep
# jq
# tar
# unzip
# xargs
# xz

# Notes:
# - Issue pages are only duplicate metadata that can be re-generated
#   from the issues themselves.
# - There are cases where files (such as attachments) are listed in
#   various json metadata files, however the may not exist in the
#   googlecode archive.  They may have been removed before googlecode
#   became read only, but I don't know for sure.

set -o errexit
set -o pipefail

LIB_BASH="$(
  readlink -f "$(
    readlink -f "$(
      dirname "$(
        readlink -f "${0}"
      )"
    )"
  )/vendor/lib-bash/src/share/lib-bash/lib.bash"
)"

if [ -f "${LIB_BASH}" ] ; then
  source "${LIB_BASH}"
elif type 'git' > /dev/null ; then
  git submodule update --init --recursive
  source "${LIB_BASH}"
else
  echo 'ERROR: lib-bash is missing'
  exit 1
fi

# URL
declare -r GSAPI='https://storage.googleapis.com'
# Buckets
declare -r ABK='google-code-archive'
declare -r ASBK='google-code-archive-source'
declare -r ATBK='google-code-attachments'
declare -r DBK='google-code-archive-downloads'
# API
# 'v2/apache-extras.org'
# 'v2/eclipselabs.org'
declare -r CGC="${API:-v2/code.google.com}"

declare -r OUTDIRDEFAULT=`pwd`
declare -r OUTDIR="${OUTDIR:-${OUTDIRDEFAULT}}"

CONCURRENT_COMPACT='true'
CONCURRENT_LIMIT='50'
declare -r ENABLE_DEBUGGING='false'

CURL_ARGS=(
  '--continue-at -'
  '--http2'
  '--http2-prior-knowledge'
  '--ssl-reqd'
  '--tlsv1.2'
  '--ciphers ECDHE-RSA-AES256-GCM-SHA384'
  '--proto -all,https'
  '--proto-redir -all,https'
  '--max-redirs 0'
  '--speed-limit 10240'
  '--speed-time 10'
  '--retry 3'
  '--retry-delay 5'
  '--compressed'
  '--create-dirs'
  # Restrict-View-* files are not contained in the archive and return 403.
  '--fail'
)

GoogleCode::Downloads.file() {
  local -r DownloadFile="${2}"
  local -r Name="${1}"

  curl ${CURL_ARGS[@]} "${GSAPI}/${DBK}/${CGC}/${Name}/${DownloadFile}" \
    -o "${OUTDIR}/${Name}/downloads/${DownloadFile}"
}

GoogleCode::Downloads.pages() {
  local -r DownloadPageNum="${2}"
  local -r Name="${1}"

  curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ABK}/${CGC}/${Name}/downloads-page-${DownloadPageNum}.json" \
    -o "${OUTDIR}/${Name}/downloads/downloads-page-${DownloadPageNum}.json"
}

# TODO: vailidate download against provided sha1 hash
GoogleCode::Downloads() {
  local -a CCArgs
  local DownloadFile
  local DownloadFiles
  local DownloadPages
  local Name="${1}"
  local TMPDIR

  TMPDIR=`mktemp -d`

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/downloads-page-1.json"
  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/downloads-page-1.json" \
    -o "${TMPDIR}/downloads-page-1.json"

  if [ ! -f "${TMPDIR}/downloads-page-1.json" ] ; then
    Log::Message 'info' 'project has no downloads'
    return 0
  fi

  DownloadPages="$(jq -r -c -M '.totalPages' "${TMPDIR}/downloads-page-1.json")"

  for i in `seq 1 ${DownloadPages}` ; do
    CCArgs+=(
      '-'
      "fetching: downloads-page-${i}.json"
      GoogleCode::Downloads.pages
        "${Name}"
        "${i}"
    )
  done

  GoogleCode::Step 'fetching download pages'

  concurrent "${CCArgs[@]}"

  while read DownloadPageFile ; do
    while read DownloadFile ; do
      DownloadFiles="${DownloadFiles}${DownloadFiles:+,}${DownloadFile}"
    done < <(jq -r -c -M '.downloads[].filename' "${DownloadPageFile}")
  done < <(find "${OUTDIR}/${Name}/downloads" -type f -name '*downloads-page*.json')

  GoogleCode::Step 'fetching downloads'

  curl ${CURL_ARGS[@]} "${GSAPI}/${DBK}/${CGC}/${Name}/\\{${DownloadFiles}\\}" \
    -o "${OUTDIR}/${Name}/downloads/#1"
}

GoogleCode::Issues.attachment() {
  local -r File="${4}"
  local -r IssueCommentNum="${3}"
  local -r IssueNum="${2}"
  local -r Name="${1}"

  curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ATBK}/${Name}/issue-${IssueNum}/comment-${IssueCommentNum}/${File}" \
    -o "${OUTDIR}/${Name}/issues/${IssueNum}/${IssueCommentNum}/${File}"
}

GoogleCode::Issues() {
  local Attachment
  local -a Attachments
  local -a CCArgs1
  local -a CCArgs2
  local IssueCommentNum
  local IssueNum
  local -a IssuePagesArray
  local Name="${1}"
  local NumIssues
  local NumIssuesRange
  local NumPages
  local NumPagesRange
  local TMPDIR

  TMPDIR=`mktemp -d`

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/issues-page-1.json"
  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/issues-page-1.json" \
    -o "${TMPDIR}/issues.json"

  if [ ! -f "${TMPDIR}/issues.json" ] ; then
    Log::Message 'info' 'project contains no issues'
    return 0
  fi

  NumIssues="$(jq -r -c -M 'first(.issues[].id)' "${TMPDIR}/issues.json")"
  NumPages="$(jq -r -c -M '.totalPages' "${TMPDIR}/issues.json")"

  Var::Type.integer "${NumIssues}"
  Var::Type.integer "${NumPages}"

  # Curl can't glob [1-1]
  if [ ${NumPages} -gt 1 ] ; then
    NumPagesRange="[1-${NumPages}]"
  fi

  eval curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ABK}/${CGC}/${Name}/issues-page-${NumPagesRange:-NumPages}.json" \
    -o "${OUTDIR}/${Name}/issues/issues-page-#1.json"

  # Curl can't glob [1-1]
  if [ ${NumIssues} -gt 1 ] ; then
    NumIssuesRange="[1-${NumIssues}]"
  fi

  eval curl ${CURL_ARGS[@]} \
    "${GSAPI}/${ABK}/${CGC}/${Name}/issues/issue-${NumIssuesRange:-NumIssues}.json" \
    -o "${OUTDIR}/${Name}/issues/#1/issue-#1.json"

  GoogleCode::Step 'compiling list of attachments'

  while read IssueFile ; do
    if [ ! -f "${IssueFile}" ] ; then
      continue
    fi

    IssueNum="$(jq -r -c -M '.id' "${IssueFile}")"
    Var::Type.integer "${IssueNum}"

    jq -r -c -M '.comments' "${IssueFile}" > "${TMPDIR}/IssueCommentJson"

    while read IssueCommentNum ; do
      Var::Type.integer "${IssueCommentNum}"

      jq -r -c -M ".[]|select(.id | contains(${IssueCommentNum}))|.attachments" \
        "${TMPDIR}/IssueCommentJson" > \
        "${TMPDIR}/IssueAttachmentsJson"

      while read IssueAttachmentFile ; do
        Attachments+=("${IssueAttachmentFile}")
      done < <(jq -r -c -M '.[]|.fileName' "${TMPDIR}/IssueAttachmentsJson")

      for Attachment in "${Attachments[@]}" ; do
        CCArgs2+=(
          '-'
          "fetching issue: ${IssueNum}, comment: ${IssueCommentNum}, attachment: ${Attachment}"
          GoogleCode::Issues.attachment
            "${Name}"
            "${IssueNum}"
            "${IssueCommentNum}"
            "${Attachment}"
        )
      done
      unset Attachments
    done < <(jq -r -c -M '.[]|.id' "${TMPDIR}/IssueCommentJson")
  done < <(find "${OUTDIR}/${Name}/issues" -type f -name '*issue-*.json')

  GoogleCode::Step 'fetching issue attachements'

  [ ${#CCArgs2[@]} -ge 1 ] || return 0

  concurrent "${CCArgs2[@]}"
}

GoogleCode::Logo() {
  local Name="${1}"

  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/logo.png" \
    -o "${OUTDIR}/${Name}/logo.png"
}

GoogleCode::ProjectJson() {
  local -r Name="${1}"

  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/project.json" \
    -o "${OUTDIR}/${Name}/project.json"
}

# TODO: add support for sub repos, requires parsing project.json
# FIXME: check hasSource from project.json
GoogleCode::Repos() {
  local -r Name="${1}"
  local HasSource
  local TMPDIR

  TMPDIR=`mktemp -d`

  HasSource="$(jq -r -c -M '.hasSource' "${OUTDIR}/${Name}/project.json")"

  [ "${HasSource}" == 'true' ] || return 0

  GoogleCode::Step 'fetching source code archive'

  curl ${CURL_ARGS[@]} "${GSAPI}/${ASBK}/${CGC}/${Name}/source-archive.zip" \
    -o "${TMPDIR}/source-archive.zip"

  unzip -q "${TMPDIR}/source-archive.zip" -d "${OUTDIR}/${Name}/repo/"
}

GoogleCode::RemoveEmpty() {
  local Directory
  local -a Directories
  local IconSize
  local -r Name="${1}"
  local OutDirSize
  local ProjectJsonSize
  local TotalBytes

  sizeOf() {
    local -r Input="${1}"
    du -bs "${Input}" | awk '{print $1;exit}'
  }

  isEmpty() {
    local -r Dir="${1}"
    [ $(sizeOf "${Dir}") -eq 0 ] && return 0
    return 1
  }

  if [ -f "${OUTDIR}/${Name}/logo.png" ] ; then
    IconSize=$(sizeOf "${OUTDIR}/${Name}/logo.png")
  fi
  OutDirSize=$(sizeOf "${OUTDIR}/${Name}")
  ProjectJsonSize=$(sizeOf "${OUTDIR}/${Name}/project.json")
  TotalBytes=$(( ${OutDirSize} - ${ProjectJsonSize} ${IconSize:+- ${IconSize}} ))
  # If the total number of bytes after subtracting logo,png & project.json
  # is less than 200 assume the project is empty an don't archive it.
  [ ${TotalBytes} -lt 200 ] && {
    Directory::Remove "${OUTDIR}/${Name}"
    return 1
  }

  while read Directory ; do
    if isEmpty "${Directory}" ; then
      Directories+=("${Directory}")
    fi
  done < <(
    # Don't risk collapsing VCS directories
    find "${OUTDIR}/${Name}" -type d -not -path "${OUTDIR}/${Name}/repo/*"
  )

  echo 'Removing empty directories:'
  printf '%s\n' "${Directories[@]}"

  # Sort directories by length, this works back up the directory
  # structure to prevent removing a parent before a child.
  echo "${Directories[@]}" |
    awk '{ print length(), $0 | "sort -n -r" }' |
    xargs rm -rf

  return 0
}

GoogleCode::Step() {
  local -r Step="${1}"

  echo "########## ${Step} ##########">&1
}

GoogleCode::TarOutput() {
  local -r Name="${1}"

  File::Remove "${OUTDIR}/${Name}.tar.xz"

  # Before taring check that there is anything to tar and
  # remove any empty directories.
  GoogleCode::Step 'collapsing empty directories'
  GoogleCode::RemoveEmpty "${Name}" || return 0

  GoogleCode::Step 'tarring output'

  # Prevent full directory heirarchy from being included, use
  # a relative path.
  pushd "${OUTDIR}" > /dev/null
    tar -cf - "${Name}" |
      xz \
        -9 \
        --compress \
        --extreme \
        --threads 1 \
        - > "${Name}.tar.xz"
  popd > /dev/null

  Directory::Remove "${OUTDIR}/${Name}"
}

GoogleCode::Wikis() {
  local -a CCArgs
  local -r Name="${1}"
  local TMPDIR
  local WikiFile
  local -a WikiFiles

  TMPDIR=`mktemp -d`

  Log::Message 'info' "${GSAPI}/${ABK}/${CGC}/${Name}/wikis.json"
  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/wikis.json" \
    -o "${TMPDIR}/wikis.json"

  if [ ! -f "${TMPDIR}/wikis.json" ] ; then
    Log::Message 'info' 'project contains no wikis'
    return 0
  fi

  # Make sure not to interate over null
  [ -z "$(cat "${TMPDIR}/wikis.json" |
          grep -o '{"WikiFiles":null}' || :)" ] || return 0

  while read WikiFile ; do
    # Remove leading slash
    WikiFile="$(echo "${WikiFile}" | sed -e 's,^/,,')"
    WikiFiles+=("${WikiFile}")
  done < <(jq -r '.WikiFiles[]' "${TMPDIR}/wikis.json")

  for i in "${WikiFiles[@]}" ; do
    if [ -n "${i}" ] ; then
      CCArgs+=(
        '-'
        "fetching wiki page: ${i}"
        GoogleCode::Wikis.page
          "${Name}"
          "${i}"
      )
    fi
  done

  [ ${#CCArgs[@]} -ge 1 ] || return 0

  GoogleCode::Step 'fetching wiki pages'

  concurrent "${CCArgs[@]}"
}

GoogleCode::Wikis.page() {
  local -r Name="${1}"
  local -r File="${2}"

  curl ${CURL_ARGS[@]} "${GSAPI}/${ABK}/${CGC}/${Name}/wiki/${File}" \
    -o "${OUTDIR}/${Name}/wikis/${File}"
}

GoogleCode::Project() {
  local -r Name="${1}"

  # Incase file were left from a previous run remove them to prevent
  # unwanted files.
  Directory::Remove "${OUTDIR}/${Name}" || return 1

  GoogleCode::ProjectJson "${Name}" || return 1

  GoogleCode::Step "checking for downloads"
  GoogleCode::Downloads "${Name}" || return 1

  GoogleCode::Step "checking for issues"
  GoogleCode::Issues "${Name}" || return 1

  GoogleCode::Step 'fetching logo'
  GoogleCode::Logo "${Name}" || return 1

  GoogleCode::Repos "${Name}" || return 1

  GoogleCode::Step 'checking for wikis'
  GoogleCode::Wikis "${Name}" || return 1

  GoogleCode::TarOutput "${Name}" || return 1
}

GoogleCode::Main() {
  local -r Name="${1}"
  local -i Try=1

  # TCP connections could be dropped and it isn't worth implementing
  # detection for this, so loop until the program succeeds.
  while [ ${Try} -eq 1 ] ; do
    GoogleCode::Project "${Name}" || {
      continue
    }
    Try=0
  done

  return 0
}

if [ -f "${1}" ] ; then
  # TODO: support reading in file
  :
else
  [ -n "${1}" ] || {
    Log::Message 'error' "no input"
    exit 1
  }
  GoogleCode::Main "${1}"
fi

exit 0
